<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Gautam Chandrasekaran</title>
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap');
    body {
      margin: 0;
      font-family: 'Inter', sans-serif;
      display: flex;
      height: 100vh;
    }
    .left {
      width: 35%;
      background-color: #f5f5f5;
      padding: 20px;
      box-sizing: border-box;
      position: fixed;
      height: 100vh;
      overflow-y: auto;
    }
    .right {
      margin-left: 35%;
      padding: 20px;
      width: 65%;
      height: 100vh;
      overflow-y: scroll;
      box-sizing: border-box;
    }
    .profile-pic {
      max-width: 60%;
      height: auto;
      border-radius: 8px;
      display: block;
      margin: 0 auto 10px auto;
    }
    ul li {
      margin-bottom: 1.5em;
      line-height: 1.6;
    }
  </style>
</head>
<body>
  <div class="left">
    <img src="/assets/website_pic.jpg" alt="Profile Picture" class="profile-pic"><br>
    <h1>Gautam Chandrasekaran</h1>
    <p>Email: gautamc at cs dot utexas dot edu</p>
    <p><a href="https://www.linkedin.com/in/gautam-chandrasekaran-5139a1188/">LinkedIn</a> | <a href="https://scholar.google.com/citations?user=-CNU0tAAAAAJ&hl=en">Google Scholar</a></p>
  </div>

  <div class="right">
    <h2>About Me</h2>
    <p>I am a fourth-year Ph.D student in the <a href="https://www.cs.utexas.edu/research/theoretical-computer-science">Computer Science Theory Group</a> at UT Austin. I am fortunate to be advised by <a href="https://www.cs.utexas.edu/~klivans/">Adam Klivans</a> and <a href="https://www.cs.utexas.edu/~diz/">David Zuckerman</a>. I am mainly interested in Learning Theory and Complexity Theory.</p>
    <p>I received a B.Tech+M.Tech in Computer Science from IIT Madras in 2022 where I was advised by <a href="http://www.cse.iitm.ac.in/~jayalal/">Jayalal Sarma</a>.</p>

    <h2>Publications (authors in alphabetical order)</h2>
    <ul>
      <li>
        <b>Learning Juntas under Markov Random Fields</b><br>
        Gautam Chandrasekaran, Adam Klivans<br>
        <em>NeurIPS 2025 (to appear)</em><br>
        <a href="https://www.arxiv.org/pdf/2506.00764">arXiv</a>
      </li>

      <li>
        <b>Learning the Sherrington-Kirkpatrick Model Even at Low Temperature</b><br>
        Gautam Chandrasekaran, Adam Klivans<br>
        <em>STOC 2025</em><br>
        <a href="https://arxiv.org/abs/2411.11174">arXiv</a>
      </li>

      <li>
        <b>Learning Neural Networks with Distribution Shift: Efficiently Certifiable Guarantees</b><br>
        Gautam Chandrasekaran, Adam Klivans, Lin Lin Lee, Konstantinos Stavropoulos<br>
        <em>ICLR 2025</em><br>
        <a href="https://arxiv.org/abs/2502.16021">arXiv</a>
      </li>

      <li>
        <b>Learning Noisy Halfspaces with a Margin: Massart is No Harder than Random</b><br>
        Gautam Chandrasekaran, Vasilis Kontonis, Konstantinos Stavropoulos, Kevin Tian<br>
        <em>NeurIPS 2024 (Spotlight)</em><br>
        <a href="https://arxiv.org/abs/2501.09851">arXiv</a>
      </li>

      <li>
        <b>Efficient Discrepancy Testing for Learning with Distribution Shift</b><br>
        Gautam Chandrasekaran, Adam Klivans, Vasilis Kontonis, Konstantinos Stavropoulos, Arsen Vasilyan<br>
        <em>NeurIPS 2024</em><br>
        <a href="https://arxiv.org/abs/2406.09373">arXiv</a>
      </li>

      <li>
        <b>Smoothed Analysis for Learning Concepts with Low Intrinsic Dimension</b><br>
        Gautam Chandrasekaran, Adam Klivans, Vasilis Kontonis, Raghu Meka, Konstantinos Stavropoulos<br>
        <em>COLT 2024</em><br>
        <b>Best Paper Award</b><br>
        <a href="http://arxiv.org/abs/2407.00966">arXiv</a>
      </li>

      <li>
        <b>Learning in online MDPs: is there a price for handling the communicating case?</b><br>
        Gautam Chandrasekaran, Ambuj Tewari<br>
        <em>UAI 2023</em><br>
        <a href="https://arxiv.org/abs/2111.02024">arXiv</a>
      </li>
    </ul>
  </div>
</body>
</html>
